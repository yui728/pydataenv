{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 自然言語の処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.1 必要なライブラリのインストール"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pythonで自然言語処理を実行するライブラリ\n",
    "* [MeCab](http://taku910.github.io/mecab/)\n",
    "  * 定番の形態素解析エンジン\n",
    "* [Janome](http://mocobeta.github.io/janome/)\n",
    "  * Pythonで書かれた辞書を内包する形態素解析エンジン\n",
    "  * 依存するライブラリが無いため、簡単にインストールできる\n",
    "* [gensim](https://radimrehurek.com/gensim/)\n",
    "  * 文書のトピックモデル（文書が扱うトピックを推定するモデル）を実行するライブラリ\n",
    "  * Word2Decなどの手法も提供\n",
    "    * Word2Dec\n",
    "      * 深層学習を用いて単語を分散表現と呼ばれるベクトルで表現\n",
    "      * ベクトル表現することにより、単語の意味の近さを計算したり、関係性の足し算や引き算が可能になる\n",
    "* [NLTK](https://www.nltk.org/)\n",
    "  * 自然言語処理全般をサポートするライブラリ\n",
    "  * 英語で形態素解析処理を行う場合に使用される"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.2 形態素解析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mecabコマンド\n",
    "1. ターミナル（windowsの場合はコマンドプロンプト）から`mecab`コマンドを実行する\n",
    "1. 適当な文を入力し、mecabで形態素解析を実行する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mecab-pythonライブラリ\n",
    "* `mecab-python`ライブラリ（windowsの場合は`mecab-python-windows`ライブラリ）を用いてPythonで形態素解析を実行する\n",
    "\n",
    "\n",
    "1. Taggerクラスをインスタンス化する\n",
    "1. parseメソッドに文を文字列で指定する\n",
    "1. ChaSenを用いた形態素解析の出力形式で実行される"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MeCab.Taggerクラス\n",
    "* 形態素解析を行うためのクラス\n",
    "* 第1引数：文字列を渡し、出力形式を指定する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MeCab.Tagger.parseメソッド\n",
    "* 形態素解析を実行し、Taggerクラスのインスタンス作成時に指定した出力形式で結果を取得する\n",
    "* 第1引数：文字列を渡し、形態素解析を行いたい文章を指定する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MeCab.Taggerクラスのインスタンスを作成し、MeCabを用いた形態素解析を実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "吾輩\tワガハイ\t吾輩\t名詞-代名詞-一般\t\t\n",
      "は\tハ\tは\t助詞-係助詞\t\t\n",
      "猫\tネコ\t猫\t名詞-一般\t\t\n",
      "で\tデ\tだ\t助動詞\t特殊・ダ\t連用形\n",
      "ある\tアル\tある\t助動詞\t五段・ラ行アル\t基本形\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "text = '吾輩は猫である'\n",
    "# 形態素解析の結果をChasenの出力形式で表示\n",
    "t = MeCab.Tagger('-Ochasen')\n",
    "result = t.parse(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "形態素解析の実行結果を出力する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'吾輩\\tワガハイ\\t吾輩\\t名詞-代名詞-一般\\t\\t\\nは\\tハ\\tは\\t助詞-係助詞\\t\\t\\n猫\\tネコ\\t猫\\t名詞-一般\\t\\t\\nで\\tデ\\tだ\\t助動詞\\t特殊・ダ\\t連用形\\nある\\tアル\\tある\\t助動詞\\t五段・ラ行アル\\t基本形\\nEOS\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mecab-pythonライブラリでの形態素解析実行結果\n",
    "1. `\\n`：行の区切り\n",
    "1. `\\t`：要素の区切り\n",
    "\n",
    "\n",
    "したがって、以下の通り分割する\n",
    "1. `\\n`で行ごとに分割\n",
    "1. `\\t`で要素ごとに分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "形態素解析の実行結果を分割する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['吾輩', 'ワガハイ', '吾輩', '名詞-代名詞-一般', '', '']\n",
      "['は', 'ハ', 'は', '助詞-係助詞', '', '']\n",
      "['猫', 'ネコ', '猫', '名詞-一般', '', '']\n",
      "['で', 'デ', 'だ', '助動詞', '特殊・ダ', '連用形']\n",
      "['ある', 'アル', 'ある', '助動詞', '五段・ラ行アル', '基本形']\n"
     ]
    }
   ],
   "source": [
    "# 形態素解析の結果を、改行を区切りとして行ごとに分割\n",
    "results = result.splitlines()\n",
    "# EOSの行は対象外とする\n",
    "for res in results[:-1]:\n",
    "    # タブを区切りとして各要素に分割\n",
    "    res_split = res.split('\\t')\n",
    "    print(res_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.3 Bag of Words（BoW）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Wordsとは\n",
    "* 各文書の形態素解析をの結果をもとに、単語ごとに出現回数をカウントしたもの"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の3つの文書に対してMeCabを用いて形態素解析を行う\n",
    "* 子供が走る\n",
    "* 車が走る\n",
    "* 子供の脇を車が走る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['子供', 'が', '走る'], ['車', 'が', '走る'], ['子供', 'の', '脇', 'を', '車', 'が', '走る']]\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "\n",
    "documents = ['子供が走る', '車が走る', '子供の脇を車が走る']\n",
    "\n",
    "words_list = []\n",
    "\n",
    "# 形態素解析の結果をChasenの出力形式で表示\n",
    "t = MeCab.Tagger('-Ochasen')\n",
    "\n",
    "# 各文に形態素解析を実行\n",
    "for s in documents:\n",
    "    s_parsed = t.parse(s)\n",
    "    words_s = []\n",
    "    # 各文の形態素をリストにまとめる\n",
    "    for line in s_parsed.splitlines()[:-1]:\n",
    "        words_s.append(line.split('\\t')[0])\n",
    "    words_list.append(words_s)\n",
    "    \n",
    "print(words_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "形態素解析の結果から、単語と1対1で対応する整数を保持する辞書を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'子供': 0, 'が': 1, '走る': 2, '車': 3, 'の': 4, '脇': 5, 'を': 6}\n"
     ]
    }
   ],
   "source": [
    "# 生成する辞書\n",
    "word2int = {}\n",
    "i = 0\n",
    "\n",
    "# 各文書の単語のリストに対して処理を反復\n",
    "for words in words_list:\n",
    "    # 文書内の各単語に対して処理を反復\n",
    "    for word in words:\n",
    "        # 単語が辞書に含まれていれば追加して対応する整数を割り当てる\n",
    "        if word not in word2int:\n",
    "            word2int[word] = i\n",
    "            i += 1\n",
    "            \n",
    "print(word2int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "辞書からBoWを計算し、文書×単語の行列を生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# BoWを計算し、文書×単語の行列を生成\n",
    "bow = np.zeros((len(words_list), len(word2int)), dtype = np.int)\n",
    "# 各行の単語を抽出し単語の出現回数をカウント\n",
    "for i, words in enumerate(words_list):\n",
    "    for word in words:\n",
    "        bow[i, word2int[word]] += 1\n",
    "\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成した行列をpandasのDataFrameに変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>子供</th>\n",
       "      <th>が</th>\n",
       "      <th>走る</th>\n",
       "      <th>車</th>\n",
       "      <th>の</th>\n",
       "      <th>脇</th>\n",
       "      <th>を</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   子供  が  走る  車  の  脇  を\n",
       "0   1  1   1  0  0  0  0\n",
       "1   0  1   1  1  0  0  0\n",
       "2   1  1   1  1  1  1  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(bow, columns = list(word2int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gensimライブラリを用いた計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gensim.corpora.Dictionaryクラス\n",
    "* gensimライブラリを用いてBag of Wordsを計算するための辞書を作成する\n",
    "* 第1引数：ワードリスト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gensimライブラリを用いた辞書の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(7 unique tokens: ['が', '子供', '走る', '車', 'の']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "# 辞書を作成する\n",
    "word2int_gs = corpora.Dictionary(words_list)\n",
    "print(word2int_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gensim.corpora.Dictionary.token2id属性\n",
    "* 作成した辞書の単語と整数の対応辞書を取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'が': 0, '子供': 1, '走る': 2, '車': 3, 'の': 4, 'を': 5, '脇': 6}\n"
     ]
    }
   ],
   "source": [
    "# 単語と整数の対応\n",
    "print(word2int_gs.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gensim.corpora.Dictionary.doc2bowメソッド\n",
    "* 作成した辞書を用いて、Bag of Wordsを取得する\n",
    "* 第1引数：解析対象の文章\n",
    "\n",
    "\n",
    "**取得したBag od Wordsについて**\n",
    "* リストの1要素：辞書内の単語に振られた番号と出現回数のタプル\n",
    "* タプルの要素\n",
    "  1. 辞書内の単語に振られた番号\n",
    "  1. 出現回数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作成した辞書を用いて、Bag of Wordsを取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1)]\n"
     ]
    }
   ],
   "source": [
    "# 1番めの文書に含まれる単語の出現回数をカウント\n",
    "print(word2int_gs.doc2bow(words_list[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gensim.matutils.corpus2dense関数\n",
    "* 辞書からの処理を繰り返して適用し、文書×単語の行列を生成する\n",
    "* 第1引数：繰り返す処理のリスト\n",
    "* num_terms引数\n",
    "  * 数値を渡し、単語数を指定する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corpus2dense関数を用いて、複数の文書のBoWを計算した行列を生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 0 0 0]\n",
      " [1 0 1 1 0 0 0]\n",
      " [1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gensim import matutils\n",
    "# Bag of Wordsを計算し、文書×単語の行列を生成\n",
    "bow_gs = np.array(\n",
    "    [matutils.corpus2dense(\n",
    "        [word2int_gs.doc2bow(words)],\n",
    "        num_terms = len(word2int)).T[0]\n",
    "        for words in words_list]\n",
    ").astype(np.int)\n",
    "\n",
    "print(bow_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成した行列を、pandasのDataFrameに変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>が</th>\n",
       "      <th>子供</th>\n",
       "      <th>走る</th>\n",
       "      <th>車</th>\n",
       "      <th>の</th>\n",
       "      <th>を</th>\n",
       "      <th>脇</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   が  子供  走る  車  の  を  脇\n",
       "0  1   1   1  0  0  0  0\n",
       "1  1   0   1  1  0  0  0\n",
       "2  1   1   1  1  1  1  1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandasのデータフレームに変換\n",
    "bow_gs_df = pd.DataFrame(bow_gs, columns = list(word2int_gs.values()))\n",
    "\n",
    "bow_gs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learnを用いた計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn.feature_extraction.text.CountVectorizerクラス\n",
    "* scikit-learnでBag of Wordsを計算するためのクラス"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単語をスペース区切りで並べた文を生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['子供 が 走る' '車 が 走る' '子供 の 脇 を 車 が 走る']\n"
     ]
    }
   ],
   "source": [
    "words_split = np.array([' '.join(words) for words in words_list])\n",
    "\n",
    "print(words_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn.feature_extraction.text.CountVectorizer.fit_transformメソッド\n",
    "* Bag of Wordsを計算した結果を取得する\n",
    "* 第1引数：解析対象の文（単語ごとにスペース区切りしたもの）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learnを用いてBoWを計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Bag od Wordsを計算\n",
    "vectorizer = CountVectorizer(token_pattern = u'(?u)\\\\b\\\\w+\\\\b')\n",
    "bow_vec = vectorizer.fit_transform(words_split)\n",
    "\n",
    "# Numpy配列に変換\n",
    "bow_vec.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn.feature_extraction.text.CountVectorizer.get_feature_namesメソッド\n",
    "* BoWを表す行列の各列が対応する単語の配列を取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['が', 'の', 'を', '子供', '脇', '走る', '車']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learnで生成したBoWの行列をpandasのDetaFrameに変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>が</th>\n",
       "      <th>の</th>\n",
       "      <th>を</th>\n",
       "      <th>子供</th>\n",
       "      <th>脇</th>\n",
       "      <th>走る</th>\n",
       "      <th>車</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   が  の  を  子供  脇  走る  車\n",
       "0  1  0  0   1  0   1  0\n",
       "1  1  0  0   0  0   1  1\n",
       "2  1  1  1   1  1   1  1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(bow_vec.toarray(), columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.4 TF-IDF\n",
    "* TF-IDF（Term Frequency-Inverse Document Frequency）\n",
    "  * すべての文書に出現する単語と、一部の文書にしか出現しない単語を区別するための方法を提供する\n",
    "  * カウントされた単語の出現回数に重みが付けられる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 直感的な説明\n",
    "* TF：Term Frequency\n",
    "  * ある1つの文書の1つの単語に対して定まる指標\n",
    "  * 「1つの文書の中に現れる全単語の合計出現回数のうち、1つの単語がどれだけの割合で出現したか」を定量化する指標\n",
    "* IDF：Inverse Document Frequency\n",
    "  * 1つの単語に対して定まる指標\n",
    "  * 「ある単語が出現する文書が文書全体の中でどれくらいの割合を占めていたか」を定量化する指標\n",
    "  * 実際にはその単語が文書全体でなく、一部のの文書にしか現れなかった度合い\n",
    "* TF-IDF\n",
    "  * TFとIDFの掛け算で定義される：$TF-IDF = TF \\times IDF$\n",
    "  * 以下の条件の時、高い値をとる\n",
    "    * 対象とする単語が1つの文書の中で大量に出現する\n",
    "    * しかし、その単語は文書全体で頻繁に現れるわけではなく、一部の特定の文書にしか現れない\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数式による説明\n",
    "* 文書$d$で単語$t$が出現する回数を$n_d,_t$、単語tが出現する文書数を$df_t$、全体の文書数を$N$、単語数を$T$とした時、<br />TF-IDFは以下の式で表すことができる\n",
    "  * $TF-IDF_d,_t = TF_d,_t \\times IDF_t$\n",
    "* TFの計算\n",
    "  * 文書$d$で出現する単語の合計出現回数のうち、単語$t$が出現する割合として定義される\n",
    "  * $\\therefore TF_d,_t = \\frac{n_d,_t}{\\sum_{t=1}^T n_d,_t}$\n",
    "* IDFの計算\n",
    "  * 単語$t$が出現する文書数$df_t$の全体の文書数$N$に対する割合の逆数に対して、対数をとったものとして定義される\n",
    "  * $\\therefore IDF_t = \\log\\frac{N}{df_t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learnを用いた計算\n",
    "\n",
    "\n",
    "#### sklearm.feature_extraction.text.TfidfTransformerクラス\n",
    "* TFについては以下の数式（各文書の単語の出現回数）として定義されている\n",
    "  * $TF_d,_t = n_d,_t$\n",
    "* IDFの計算方法については、複数提供されている\n",
    "* TF-IDFの計算方法に工夫が行われ、IDFの計算後に正規化が行われる\n",
    "* use_idfパラメータ\n",
    "  * True：以下の数式で計算\n",
    "    * $IDF_t = \\log{\\frac{N+1}{df_t+1}}$\n",
    "    * すべての単語で0以外の値となるようにし、ゼロ除算による計算結果の不定、不能を回避する\n",
    "  * False：以下の数式で計算\n",
    "    * $IDF_t = \\log\\frac{N}{df_t}$\n",
    "* smooth_idfパラメータ\n",
    "  * True：以下の数式で計算\n",
    "    * $TF-IDF_{d,t} = TF_d,_t \\times (IDF_t + 1)$\n",
    "    * すべての文に出現する単語（$IDF = 0$となる）も完全には無視しないようにする\n",
    "  * False：以下の数式で計算\n",
    "    * $TF-IDF_{d,t} = TF_{d,t} \\times IDF_t$\n",
    "* 正規化\n",
    "  * デフォルトのL2正規化を行った結果、TF-IDFを正規化したTD-IDF normilizedは以下の式で表現できる\n",
    "    * $TF-IDF normilized \\\\= \\frac{TF-IDF_{d,t}}{\\sqrt{(TF-IDF_{d,1})^2+(TF-TDF_{d,2})^2+...+(TF-IDF_{d,T})^2}} \\\\= \\frac{TF-IDF_{d,t}}{\\sqrt{\\sum_{j=1}^{T}(TF-IDF_{d,j})^2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDFの計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各文書に出現する単語の頻度を保持するデータを再確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>が</th>\n",
       "      <th>子供</th>\n",
       "      <th>走る</th>\n",
       "      <th>車</th>\n",
       "      <th>の</th>\n",
       "      <th>を</th>\n",
       "      <th>脇</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   が  子供  走る  車  の  を  脇\n",
       "0  1   1   1  0  0  0  0\n",
       "1  1   0   1  1  0  0  0\n",
       "2  1   1   1  1  1  1  1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_gs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFを計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 0 0 0]\n",
      " [1 0 1 1 0 0 0]\n",
      " [1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# TFとしてBoWを使用\n",
    "tf = bow_gs\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDFを計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.28768207 0.         0.28768207 0.69314718 0.69314718\n",
      " 0.69314718]\n"
     ]
    }
   ],
   "source": [
    "# IDFを計算\n",
    "idf = np.log((bow_gs.shape[0] + 1) / (np.sum(bow_gs, axis = 0, keepdims = 0) + 1))\n",
    "\n",
    "print(idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDFを計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52284231 0.67325467 0.52284231 0.         0.         0.\n",
      "  0.        ]\n",
      " [0.52284231 0.         0.52284231 0.67325467 0.         0.\n",
      "  0.        ]\n",
      " [0.26806191 0.34517852 0.26806191 0.34517852 0.45386827 0.45386827\n",
      "  0.45386827]]\n"
     ]
    }
   ],
   "source": [
    "# TF-IDFを計算\n",
    "tf_idf = tf * ( idf + 1 )\n",
    "tf_idf_normalized = tf_idf / np.sqrt(np.sum(tf_idf ** 2, axis = 1, keepdims = True))\n",
    "\n",
    "print(tf_idf_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandasのDataFrameに変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>が</th>\n",
       "      <th>子供</th>\n",
       "      <th>走る</th>\n",
       "      <th>車</th>\n",
       "      <th>の</th>\n",
       "      <th>を</th>\n",
       "      <th>脇</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.522842</td>\n",
       "      <td>0.673255</td>\n",
       "      <td>0.522842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.522842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522842</td>\n",
       "      <td>0.673255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.268062</td>\n",
       "      <td>0.345179</td>\n",
       "      <td>0.268062</td>\n",
       "      <td>0.345179</td>\n",
       "      <td>0.453868</td>\n",
       "      <td>0.453868</td>\n",
       "      <td>0.453868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          が        子供        走る         車         の         を         脇\n",
       "0  0.522842  0.673255  0.522842  0.000000  0.000000  0.000000  0.000000\n",
       "1  0.522842  0.000000  0.522842  0.673255  0.000000  0.000000  0.000000\n",
       "2  0.268062  0.345179  0.268062  0.345179  0.453868  0.453868  0.453868"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(tf_idf_normalized, columns = word2int_gs.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learnを用いた計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learnのfeature_extraction.textモジュールのTfidfTransformerクラスを用いてTF-IDFを計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52284231 0.67325467 0.52284231 0.         0.         0.\n",
      "  0.        ]\n",
      " [0.52284231 0.         0.52284231 0.67325467 0.         0.\n",
      "  0.        ]\n",
      " [0.26806191 0.34517852 0.26806191 0.34517852 0.45386827 0.45386827\n",
      "  0.45386827]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# TfidfTramsformerクラスをインスタンス化\n",
    "tfidf = TfidfTransformer(use_idf = True, norm = 'l2', smooth_idf = True)\n",
    "# TF-IDFを算出\n",
    "print(tfidf.fit_transform(bow_gs).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandasのDataFrameに変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>が</th>\n",
       "      <th>子供</th>\n",
       "      <th>走る</th>\n",
       "      <th>車</th>\n",
       "      <th>の</th>\n",
       "      <th>を</th>\n",
       "      <th>脇</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.522842</td>\n",
       "      <td>0.673255</td>\n",
       "      <td>0.522842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.522842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522842</td>\n",
       "      <td>0.673255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.268062</td>\n",
       "      <td>0.345179</td>\n",
       "      <td>0.268062</td>\n",
       "      <td>0.345179</td>\n",
       "      <td>0.453868</td>\n",
       "      <td>0.453868</td>\n",
       "      <td>0.453868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          が        子供        走る         車         の         を         脇\n",
       "0  0.522842  0.673255  0.522842  0.000000  0.000000  0.000000  0.000000\n",
       "1  0.522842  0.000000  0.522842  0.673255  0.000000  0.000000  0.000000\n",
       "2  0.268062  0.345179  0.268062  0.345179  0.453868  0.453868  0.453868"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(tfidf.fit_transform(bow_gs).toarray(), columns = word2int_gs.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.5 極性判定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 極性判定とは\n",
    "* それぞれの文書が肯定的（ポジティブ）か否定的（ネガティブ）かを判定するタスク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[青空文庫](https://www.aozora.gr.jp/)から[夏目漱石の「吾輩は猫である」](https://www.aozora.gr.jp/cards/000148/card789.html)をダウンロードして読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import urllib.request\n",
    "\n",
    "# 青空文庫「吾輩は猫である」のファイルをダウンロード\n",
    "urllib.request.urlretrieve('https://www.aozora.gr.jp/cards/000148/files/789_ruby_5639.zip', '789_ruby_5639.zip')\n",
    "\n",
    "# zipファイルを解凍し、データを読み込む\n",
    "with zipfile.ZipFile('789_ruby_5639.zip', 'r') as zipf:\n",
    "    data = zipf.read('wagahaiwa_nekodearu.txt')\n",
    "\n",
    "# bytesを変換\n",
    "text = data.decode('shift_jis') # shift-jisに変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reライブラリ\n",
    "* 正規表現による処理を行うためのライブラリ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reライブラリを使用して正規表現を用いることにより、ルビや注釈等を除去する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一吾輩は猫である', '名前はまだ無い', 'どこで生れたかとんと見当がつかぬ', '何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している', '吾輩はここで始めて人間というものを見た']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# ルビ、注釈、改行コード等を除去\n",
    "text = re.split(r'\\-{5,}', text)[2]\n",
    "text = text.split('底本：')[0]\n",
    "text = re.sub(r'《.+?》', '', text)\n",
    "text = re.sub(r'［＃.+?］', '', text)\n",
    "text = text.strip()\n",
    "\n",
    "# 空白文字などを除去\n",
    "text = text.replace('\\u3000', '')\n",
    "# 改行コードを除去\n",
    "text = text.replace('\\r', '').replace('\\n', '')\n",
    "# 「。」を区切り文字として分割\n",
    "sentences = text.split('。')\n",
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MeCabを用いて形態素解析を実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['一', '吾輩', 'は', '猫', 'だ', 'ある'], ['名前', 'は', 'まだ', '無い'], ['どこ', 'で', '生れる', 'た', 'か', 'とんと', '見当', 'が', 'つく', 'ぬ'], ['何', 'でも', '薄暗い', 'じめじめ', 'する', 'た', '所', 'で', '*', '泣く', 'て', 'いた事', 'だけ', 'は', '記憶', 'する', 'て', 'いる'], ['吾輩', 'は', 'ここ', 'で', '始める', 'て', '人間', 'という', 'もの', 'を', '見る', 'た'], ['しかも', 'あと', 'で', '聞く', 'と', 'それ', 'は', '書生', 'という', '人間', '中', 'で', '一番', '｜', '獰悪', 'だ', '種族', 'だ', 'ある', 'た', 'そう', 'だ'], ['この', '書生', 'という', 'の', 'は', '時々', '我々', 'を', '捕える', 'て', '煮る', 'て', '食う', 'という', '話', 'だ', 'ある'], ['しかし', 'その', '当時', 'は', '何', 'という', '考', 'も', 'ない', 'た', 'から', '別段', '恐い', 'いとも', '思う', 'ない', 'た'], ['ただ', '彼', 'の', '掌', 'に', '載せる', 'られる', 'て', 'スー', 'と', '持ち上げる', 'られる', 'た', '時', '何だか', 'フワフワ', 'する', 'た', '感じ', 'が', 'ある', 'た', 'ばかり', 'だ', 'ある'], ['掌', 'の', '上', 'で', '少し', '落ちつく', 'て', '書生', 'の', '顔', 'を', '見る', 'た', 'の', 'が', 'いわゆる', '人間', 'という', 'もの', 'の', '見る', '始', 'だ', 'ある', 'う']]\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "\n",
    "words_list = []\n",
    "\n",
    "# 各文に形態素解析を実行\n",
    "t = MeCab.Tagger('^Ochasen')\n",
    "# 各文書に対して処理を反復（最後の要素は単語がないため除外）\n",
    "for sentence in sentences[:-1]:\n",
    "    sentence_parsed = t.parse(sentence)\n",
    "    word_s = []\n",
    "    # print(sentence_parsed)\n",
    "    # 各文書に現れる単語のリストに対して処理を反復\n",
    "    for line in sentence_parsed.splitlines()[:-1]:\n",
    "        # print(line)\n",
    "        # print(line.split('\\t'))\n",
    "        word_s.append(line.split('\\t')[1].split(',')[-3])\n",
    "    words_list.append(word_s)\n",
    "    \n",
    "print(words_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[「日本語評価極性辞書」](http://www.cl.ecei.tohoku.ac.jp/index.php?Open%20Resources%2FJapanese%20Sentiment%20Polarity%20Dictionary)をダウンロードする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wago.121808.pn', <http.client.HTTPMessage at 0x1749302ec88>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 日本語評価極性辞書をダウンロードする\n",
    "urllib.request.urlretrieve('http://www.cl.ecei.tohoku.ac.jp/resources/sent_lex/wago.121808.pn', 'wago.121808.pn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandasのread_csv関数を用いて辞書を読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ネガ（経験）</td>\n",
       "      <td>あがく</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ネガ（経験）</td>\n",
       "      <td>あきらめる</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ネガ（経験）</td>\n",
       "      <td>あきる</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1\n",
       "0  ネガ（経験）    あがく\n",
       "1  ネガ（経験）  あきらめる\n",
       "2  ネガ（経験）    あきる"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 日本語評価極性辞書を読み込む\n",
    "wago = pd.read_csv('wago.121808.pn', header = None, sep = '\\t')\n",
    "wago.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 日本語評価極性辞書について\n",
    "* 以下のラベルが存在する\n",
    "\n",
    "<table style='margin-left:5px;'>\n",
    "    <tbody>\n",
    "        <tr><th>ラベル</th></tr>\n",
    "        <tr><td>ポジ（経験）</td></tr>\n",
    "        <tr><td>ポジ（評価）</td></tr>\n",
    "        <tr><td>ネガ（経験）</td></tr>\n",
    "        <tr><td>ネガ（評価）</td></tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "日本語評価極性辞書を以下の通りスコア付けする辞書を作成する\n",
    "\n",
    "<table style='margin-left: 5px;'>\n",
    "    <tbody>\n",
    "        <tr><th>ラベル</th><th>スコア</th></tr>\n",
    "        <tr><td>ポジ（経験）</td><td>1</td></tr>\n",
    "        <tr><td>ポジ（評価）</td><td>1</td></tr>\n",
    "        <tr><td>ネガ（経験）</td><td>-1</td></tr>\n",
    "        <tr><td>ネガ（評価）</td><td>-1</td></tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語とスコアを対応させる辞書を作成\n",
    "word2score = {}\n",
    "values = {'ポジ（経験）':1, 'ポジ（評価）':1, 'ネガ（経験）':-1, 'ネガ（評価）':-1}\n",
    "for word, label in zip(wago.loc[:, 1], wago.loc[:, 0]):\n",
    "    word2score[word]  = values[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作成した辞書の最初の3要素を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('あがく', -1), ('あきらめる', -1), ('あきる', -1)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最初の3要素を確認する\n",
    "list(word2score.items())[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各文書のスコアを算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "# 各文書のスコアを算出\n",
    "for words in words_list:\n",
    "    score = 0\n",
    "    # 単語が辞書に現れていれば、そのスコアを加算\n",
    "    for word in words:\n",
    "        if word in word2score:\n",
    "            score += word2score[word]\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文書とそのスコアの対応をpandasのデータフレームに格納"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>一吾輩は猫である</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>名前はまだ無い</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>どこで生れたかとんと見当がつかぬ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>吾輩はここで始めて人間というものを見た</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              sentence  score\n",
       "0                             一吾輩は猫である      0\n",
       "1                              名前はまだ無い      0\n",
       "2                     どこで生れたかとんと見当がつかぬ      0\n",
       "3  何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している     -1\n",
       "4                  吾輩はここで始めて人間というものを見た      0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame({'sentence': sentences[:-1], 'score': scores}, columns = ['sentence', 'score'])\n",
    "scores_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スコアの高い文書5件を抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>四百六十五行から、四百七十三行を御覧になると分ります」「希臘語｜云々はよした方がいい、さも希...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>「厭きっぽいのじゃない薬が利かんのだ」「それだってせんだってじゅうは大変によく利くよく利くと...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5380</th>\n",
       "      <td>精神の修養を主張するところなぞは大に敬服していい」「敬服していいかね</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3860</th>\n",
       "      <td>美しい？美しくても構わんから、美しい獣と見做せばいいのである</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3871</th>\n",
       "      <td>それほど裸体がいいものなら娘を裸体にして、ついでに自分も裸になって上野公園を散歩でもするがい...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  score\n",
       "1428  四百六十五行から、四百七十三行を御覧になると分ります」「希臘語｜云々はよした方がいい、さも希...      5\n",
       "453   「厭きっぽいのじゃない薬が利かんのだ」「それだってせんだってじゅうは大変によく利くよく利くと...      5\n",
       "5380                 精神の修養を主張するところなぞは大に敬服していい」「敬服していいかね      4\n",
       "3860                     美しい？美しくても構わんから、美しい獣と見做せばいいのである      4\n",
       "3871  それほど裸体がいいものなら娘を裸体にして、ついでに自分も裸になって上野公園を散歩でもするがい...      3"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スコアの降順に並び替える\n",
    "scores_df_sorted = scores_df.sort_values('score', ascending = False)\n",
    "# スコアの高い文書5件を抽出\n",
    "scores_df_sorted.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スコアの低い文書5件を抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7014</th>\n",
       "      <td>自殺クラブはこの第二の問題と共に起るべき運命を有している」「なるほど」「死ぬ事は苦しい、しか...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>向うがあやまるなら特別、私の方ではそんな慾はありません」「警察が君にあやまれと命じたらどうで...</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>こんな、しつこい、毒悪な、ねちねちした、執念深い奴は大嫌だ</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6618</th>\n",
       "      <td>どうもいつまで行っても柿ばかり食ってて際限がないね」「私もじれったくてね」「君より聞いてる方...</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6687</th>\n",
       "      <td>「古人を待つ身につらき置炬燵と云われた事があるからね、また待たるる身より待つ身はつらいともあ...</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  score\n",
       "7014  自殺クラブはこの第二の問題と共に起るべき運命を有している」「なるほど」「死ぬ事は苦しい、しか...     -3\n",
       "7098  向うがあやまるなら特別、私の方ではそんな慾はありません」「警察が君にあやまれと命じたらどうで...     -4\n",
       "3783                      こんな、しつこい、毒悪な、ねちねちした、執念深い奴は大嫌だ     -4\n",
       "6618  どうもいつまで行っても柿ばかり食ってて際限がないね」「私もじれったくてね」「君より聞いてる方...     -4\n",
       "6687  「古人を待つ身につらき置炬燵と云われた事があるからね、また待たるる身より待つ身はつらいともあ...     -5"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スコアの低い5件を抽出\n",
    "scores_df_sorted.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.6 まとめ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 実際の解析時に必要になること\n",
    "* 精度を高めるための工夫\n",
    "  * 形態素解析に使用するために、専用の辞書を作成する\n",
    "  * BoWを集計する際に助詞を除外する"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
